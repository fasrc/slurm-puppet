#!/n/sw/envs/seff-array/bin/python3

import argparse
import subprocess
import sys

import numpy as np
import pandas as pd

from io import StringIO
import os

import termplotlib as tpl

import json
import gzip
import base64
from typing import Optional

__version__ = 0.2
debug = False


def time_to_float(time):
    """ converts [dd-[hh:]]mm:ss time to seconds """
    if isinstance(time, float):
        return time
    days, hours = 0, 0

    if "-" in time:
        days = int(time.split("-")[0]) * 86400
        time = time.split("-")[1]
    time = time.split(":")

    if len(time) > 2:
        hours = int(time[0]) * 3600

    mins = int(time[-2]) * 60
    secs = float(time[-1])

    return days + hours + mins + secs

def get_stats_dict(ss64: Optional[str]) -> dict:
    """Convert the base64-encoded summary statistics to JSON."""
    if (not ss64) or pd.isna(ss64) or ss64 == "JS1:Short" or ss64 == "JS1:None":
        return {}
    return json.loads(gzip.decompress(base64.b64decode(ss64[4:])))

def gpu_count(js):
  gpu_cnt = 0
  if js:
    for node in js['nodes']:
      try:
        gpus = list(js['nodes'][node]['gpu_utilization'].keys())
      except Exception:
        exit
      else:
        for gpu in gpus:
          gpu_cnt = gpu_cnt + 1

  return gpu_cnt

def gpu_util(js):
  gpu_util = 0
  if js:
    for node in js['nodes']:
      try:
        gpus = list(js['nodes'][node]['gpu_utilization'].keys())
      except Exception:
        exit
      else:
        for gpu in gpus:
          util = js['nodes'][node]['gpu_utilization'][gpu]
          gpu_util = gpu_util + util/100.0

  return gpu_util

#@profile
def job_eff(user, account, starttime, endtime, cluster=os.getenv('SLURM_CLUSTER_NAME')):

    if user != None:
        fmt = '--format=JobID,JobName,Elapsed,ReqMem,ReqCPUS,Timelimit,State,TotalCPU,NNodes,User,Group,Cluster,AdminComment'
        if cluster != None:
            q = f'sacct -X --units=G -P {fmt} -u {user} -S {starttime} -E {endtime} --cluster {cluster} --state=CA,CD,F,OOM,TO'
        else:
            q = f'sacct -X --units=G -P {fmt} -u {user} -S {starttime} -E {endtime} --state=CA,CD,F,OOM,TO'
        res = subprocess.check_output([q], shell=True)
        res = str(res, 'utf-8')
        df_short = pd.read_csv(StringIO(res), sep='|')

        fmt = '--format=JobID,JobName,Elapsed,ReqMem,ReqCPUS,Timelimit,State,TotalCPU,NNodes,User,Group,Cluster,MaxRSS,AdminComment'
        if cluster != None:
            q = f'sacct --units=G -P {fmt} -u {user} -S {starttime} -E {endtime} --cluster {cluster} --state=CA,CD,F,OOM,TO'
        else:
            q = f'sacct --units=G -P {fmt} -u {user} -S {starttime} -E {endtime} --state=CA,CD,F,OOM,TO'
        res = subprocess.check_output([q], shell=True)
        res = str(res, 'utf-8')
        df_long = pd.read_csv(StringIO(res), sep='|')
    elif account != None:
        fmt = '--format=JobID,JobName,Elapsed,ReqMem,ReqCPUS,Timelimit,State,TotalCPU,NNodes,User,Group,Cluster,AdminComment'
        if cluster != None:
            q = f'sacct -a -X --units=G -P {fmt} -A {account} -S {starttime} -E {endtime} --cluster {cluster} --state=CA,CD,F,OOM,TO'
        else:
            q = f'sacct -a -X --units=G -P {fmt} -A {account} -S {starttime} -E {endtime} --state=CA,CD,F,OOM,TO'
        res = subprocess.check_output([q], shell=True)
        res = str(res, 'utf-8')
        df_short = pd.read_csv(StringIO(res), sep='|')

        fmt = '--format=JobID,JobName,Elapsed,ReqMem,ReqCPUS,Timelimit,State,TotalCPU,NNodes,User,Group,Cluster,MaxRSS,AdminComment'
        if cluster != None:
            q = f'sacct -a --units=G -P {fmt} -A {account} -S {starttime} -E {endtime} --cluster {cluster} --state=CA,CD,F,OOM,TO'
        else:
            q = f'sacct -a --units=G -P {fmt} -A {account} -S {starttime} -E {endtime} --state=CA,CD,F,OOM,TO'
        res = subprocess.check_output([q], shell=True)
        res = str(res, 'utf-8')
        df_long = pd.read_csv(StringIO(res), sep='|')


    if len(df_long) == 0:
        print(f"No jobs have completed.")
        return -1
        
    # cleaning
    df_short = df_short.fillna(0.)
    df_long  = df_long.fillna(0.)

    df_long['MaxRSS'] = df_long.MaxRSS.astype('str')
    df_long['ReqMem'] = df_long.ReqMem.astype('str')

    df_long['Timelimit'] = df_long.Timelimit.replace('UNLIMITED','365-00:00:00').replace('Partition_Limit','365-00:00:00')

    df_long['JobID'] = df_long.JobID.map(lambda x: x.split('.')[0])
    df_long['MaxRSS'] = df_long.MaxRSS.str.replace('G', '').astype('float')
    df_long['ReqMem'] = df_long.ReqMem.str.replace('G', '').astype('float')
    df_long['TotalCPU'] = df_long.TotalCPU.map(lambda x: time_to_float(x))
    df_long['Elapsed'] = df_long.Elapsed.map(lambda x: time_to_float(x))
    df_long['Timelimit'] = df_long.Timelimit.map(lambda x: time_to_float(x))
    df_short['AdminComment'] = df_short.AdminComment.map(lambda x: get_stats_dict(x))
    gpu_req = df_short.AdminComment.map(lambda x: gpu_count(x))

    # job info
    job_name = df_short['JobName'].unique()
    cluster = df_short['Cluster'][0]
    username = df_short['User'].unique()
    group = df_short['Group'][0]
    nodes = df_long.NNodes.loc[df_long.groupby('JobID')['NNodes'].idxmax()].mean()
    cores = df_long.ReqCPUS.loc[df_long.groupby('JobID')['ReqCPUS'].idxmax()].mean()
    if len(gpu_req[gpu_req != 0]) != 0:
      gpus = gpu_req[gpu_req != 0].mean()
    else:
      gpus = 0
    req_mem = df_long.ReqMem.loc[df_long.groupby('JobID')['ReqMem'].idxmax()].mean()
    req_time = df_long.Timelimit.loc[df_long.groupby('JobID')['Timelimit'].idxmax()].mean()

    job_name = ', '.join(job_name)
    username = ', '.join(username)
    
    print("--------------------------------------------------------")
    print("Job Information")
    print(f"Names: {job_name}")
    print(f"Cluster: {cluster}")
    print(f"Users: {username}")
    print(f"Account: {group}")
    print(f"Start Time: {starttime}")
    print(f"End Time: {endtime}")
    print(f"Average Requested CPUs: {cores:.2f} cores on {nodes:.2f} node(s)")
    print(f"Average Requested GPUs: {gpus:.2f}")
    print(f"Average Requested Memory: {req_mem:.2f}G")
    print(f"Average Requested Time: {req_time:.2f}s")
    print("--------------------------------------------------------")
    
    print("Job Status")
    states = np.unique(df_short['State'])
    for s in states:
        print(f"{s}: {len(df_short[df_short.State == s])}")
    print("--------------------------------------------------------")
        
    cpu_use =  df_long.TotalCPU.loc[df_long.groupby('JobID')['TotalCPU'].idxmax()]
    cpu_req =  df_long.ReqCPUS.loc[df_long.groupby('JobID')['ReqCPUS'].idxmax()]
    gpu_use = df_short.AdminComment.map(lambda x: gpu_util(x))
    time_use = df_long.Elapsed.loc[df_long.groupby('JobID')['Elapsed'].idxmax()]
    time_req = df_long.Timelimit.loc[df_long.groupby('JobID')['Timelimit'].idxmax()]
    mem_use =  df_long.MaxRSS.loc[df_long.groupby('JobID')['MaxRSS'].idxmax()]
    mem_req =  df_long.ReqMem.loc[df_long.groupby('JobID')['ReqMem'].idxmax()]
    cpu_eff = np.divide(np.divide(cpu_use.to_numpy(), time_use.to_numpy(), out=np.zeros_like(cpu_use.to_numpy()), where=time_use.to_numpy()!=0), cpu_req.to_numpy()).clip(0,1.0)
    gpu_eff = np.divide(gpu_use[gpu_req != 0].to_numpy(), gpu_req[gpu_req != 0].to_numpy()).clip(0,1.0)
    mem_eff = np.divide(mem_use.to_numpy(), mem_req.to_numpy(), out=np.zeros_like(mem_use.to_numpy()), where=mem_req.to_numpy()!=0).clip(0,1.0)
    time_eff = np.divide(time_use.to_numpy(), time_req.to_numpy(), out=np.zeros_like(time_use.to_numpy()), where=time_req.to_numpy()!=0).clip(0,1.0)

    print("--------------------------------------------------------")
    print("Job Statistics")
    print(f"Total Number of Jobs: {len(cpu_eff)}")
    print(f"Total Number of GPU Jobs: {len(gpu_eff)}")
    print(f"Average CPU Efficiency {cpu_eff.mean()*100:.2f}%")
    if len(gpu_eff) != 0:
      print(f"Average GPU Efficiency {gpu_eff.mean()*100:.2f}%")
    print(f"Average Memory Usage {mem_use.mean():.2f}G")
    print(f"Average Run-time {time_use.mean():.2f}s")
    print("---------------------")
    
    print('\nCPU Efficiency (%)\n---------------------')
    fig = tpl.figure()
    h, bin_edges = np.histogram(cpu_eff*100, bins=np.linspace(0,100,num=11))
    fig.hist(h, bin_edges, orientation='horizontal')
    fig.show()

    if len(gpu_eff) != 0:
      print('\nGPU Efficiency (%)\n---------------------')
      fig = tpl.figure()
      h, bin_edges = np.histogram(gpu_eff*100, bins=np.linspace(0,100,num=11))
      fig.hist(h, bin_edges, orientation='horizontal')
      fig.show()

    print('\nMemory Efficiency (%)\n---------------------')
    fig = tpl.figure()
    h, bin_edges = np.histogram(mem_eff*100, bins=np.linspace(0,100,num=11))
    fig.hist(h, bin_edges, orientation='horizontal')
    fig.show()
    
    print('\nTime Efficiency (%)\n---------------------')
    fig = tpl.figure()
    h, bin_edges = np.histogram(time_eff*100, bins=np.linspace(0,100,num=11))
    fig.hist(h, bin_edges, orientation='horizontal')
    fig.show()

    print("--------------------------------------------------------")

if __name__ == "__main__":

    desc = (
        """
    seff-account v%s
    https://github.com/fasrc/seff-account
    ---------------
    An extension of the Slurm command 'seff' designed to summarize job usage for users and accounts over a period of time and display information in a histogram.

    When passed a user or account (note that for accounts outside of what the user is a member of that user must be either an Operator or Administrator), this
    command produces a summary of that user or account over the period specified (default is last day). Time arguments for starttime and endtime are
    the same as the sacct command. The summary includes a list of active users, job names, average time, memory, cpu, and gpu.
    
    It also generates histograms of the efficiency of the job. For cpu efficiency the cpu time is divided by elapsed time multipled by the number of requested cores.
    For gpu efficiency it uses the results from jobstats. For memory efficiency the MaxRSS is divided by the amount of memory requested by the job. For time the
    amount of time used is divided by the time requested.
    -----------------
    """
        % __version__
    )

    parser = argparse.ArgumentParser(
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description=desc,
    )
    parser.add_argument("-u", "--user", action="store", dest="user")
    parser.add_argument("-A", "--account", action="store", dest="account")
    parser.add_argument("-S", "--starttime", action="store", dest="starttime", default="now-1days") 
    parser.add_argument("-E", "--endtime", action="store", dest="endtime", default="now")   
    parser.add_argument("-c", "--cluster", action="store", dest="cluster")
    parser.add_argument('--version', action='version',  version='%(prog)s {version}'.format(version=__version__))
    args = parser.parse_args(args=None if sys.argv[1:] else ['--help'])

    job_eff(args.user, args.account, args.starttime, args.endtime, args.cluster)
