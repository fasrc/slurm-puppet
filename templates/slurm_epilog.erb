#!/bin/sh

# We specifically don't run this with errexit ('set -e') since a nonzero
# exit status from this script will drain the host.

PROCESS_KILL_WAIT_SECS=90

PATH="$PATH:/usr/local/sbin:/sbin:/usr/sbin"

progname=${0##*/}
log() {
	logger -it "$progname"
}

slurm_jobs_running_for()
{
	local user="$1"
	shift

	local except_job="$1"
	shift

	local userid=$(id -ur $user)
	shift

	# If squeue(1) can't contact slurmctld, fail open and assume
	# the user has other jobs running. Otherwise, we'll kill all of
	# the user's other running jobs.
#	if ! output=$(/usr/bin/squeue -ho %A -u "$user" -w localhost); then
#		echo "squeue failed, assuming $user has other jobs running:" | log
#		echo "$output" | log
#		return 0
#	fi

	# Hacky version in place for now.
	if ! output=$(set -o pipefail && ls "/sys/fs/cgroup/freezer/slurm/uid_$userid" | sed -n '/job/s/job_//p'); then
		echo "ls failed, assuming $user has other jobs running:" | log
		echo "$output" | log
		return 0
	fi

	job_list="$output"

	for job_id in $job_list; do
		# Remove everything after the underscore; we want the bare job ID,
		# with no job array index.
		job_id=${job_id%%_*}

		if [ "$job_id" -ne "$except_job" ]; then
			return 0
		fi
	done

	return 1
}

# Sleep up to secs until condition evals to true.
sleep_in_steps_for()
{
	local condition="$1"
	shift

	local secs="$1"
	shift
	if ! echo "$secs" | grep -q '^[[:digit:]]\{1,\}$'; then
		echo 'sleep_in_steps_for: \$secs argument must be numeric.' 1>&2
		return 1
	fi

	if ! begin=$(date +%s); then
		return 1
	fi
	end=$(($begin + $secs))

	sleep_step=$(($secs / 10))
	if [ "$sleep_step" -lt 1 ]; then
		sleep_step=1
	fi

	while [ "$(date +%s)" -lt $end ]; do
		now=$(date +%s)
		# Don't overshoot $end.
		if [ $(($now + $sleep_step)) -gt $end ]; then
			sleep_step=$(($end - $now))
		fi

		sleep "$sleep_step"

		if eval "$condition"; then
			now=$(date +%s)
			echo $(($now - $begin))
			return 0
		fi
	done

	return 1
}

kill_leftover_user_procs()
{
	local job_user="$1"
	shift

	# Don't kill any extra processes for :rc_admin members. It's nice to be
	# able to log into a compute node to troubleshoot jobs without constantly
	# having your SSH sessions killed.
	if groups "$job_user" | grep -q '[[:space:]]rc_admin[[:space:]]'; then
		echo "$job_user is in :rc_admin, not killing other processes." | log
		return 0
	fi

	# Don't try to kill user processes if the user has other jobs running.
	if slurm_jobs_running_for "$job_user" "$SLURM_JOB_ID"; then
		echo "$job_user has other jobs running," \
			'not killing other processes.' | log
		return 0
	fi

	if ! num_user_procs=$(ps --no-headers -u "$job_user" | grep -c .); then
		# No processes left.
		echo "All of $job_user's processes already exited." | log
		return 0
	fi

	echo "Sending SIGTERM to remaining $num_user_procs process(es)" \
		"for $job_user" | log
	pkill -TERM -U "$job_user"

	# ps(1) exits with status 1 when no matching processes are found,
	# so negate that exit status for the 'success' (i.e., no more user
	# processes are running) condition.
	if slept_for=$(sleep_in_steps_for \
		"! ps --no-headers -u '$job_user'" \
		"$PROCESS_KILL_WAIT_SECS"); then

		echo "$job_user processes exited within" \
			"$slept_for seconds after SIGTERM." | log
		return 0
	fi

	num_user_procs=$(ps --no-headers -u "$job_user" | grep -c .)
	echo "Sending SIGKILL to remaining $num_user_procs process(es)" \
		"for $job_user" | log
	pkill -KILL -U "$job_user"

	if slept_for=$(sleep_in_steps_for \
		"! ps --no-headers -u '$job_user'" \
		"$PROCESS_KILL_WAIT_SECS"); then

		echo "$job_user processes exited within" \
			"$slept_for seconds after SIGKILL." | log
		return 0
	fi

	# Check for leftover user procs
	echo "$job_user still has processes running despite" \
		"waiting $PROCESS_KILL_WAIT_SECS seconds each after both" \
		'SIGTERM and SIGKILL, draining this node.' | log
	ps -u "$job_user" | log
	this_host=$(hostname -s)
	scontrol update node="$this_host" state=drain \
		reason="$job_user procs still running"
	return 1
}


setUp()
{
	rm -rf "$_TEST_TMPDIR/"*
	log() {
		# Don't log when running the test suite.
		:
	}
}

_setup_command_call_counter()
{
	local binary="$1"
	shift

	touch "$_TEST_TMPDIR/$binary-called"
	cat >"$_TEST_TMPDIR/$binary" <<EOF
#!/bin/sh

echo "\$@" >>"$_TEST_TMPDIR/$binary-called"
exit 0
EOF

	chown root:root "$_TEST_TMPDIR/$binary"
	chmod 755 "$_TEST_TMPDIR/$binary"
	export PATH="$_TEST_TMPDIR:$PATH"
}
_command_calls()
{
	local binary="$1"
	shift

	cat "$_TEST_TMPDIR/$binary-called"
}

test_slurm_jobs_running_for_other_jobs_running()
{
	cat >"$_TEST_TMPDIR/squeue" <<EOF
#!/bin/sh

cat <<EOJ
69_2
42
EOJ
EOF
	chown root:root "$_TEST_TMPDIR/squeue"
	chmod 755 "$_TEST_TMPDIR/squeue"
	export PATH="$_TEST_TMPDIR:$PATH"

	assertTrue 'slurm_jobs_running_for test_user 42'
}
test_slurm_jobs_running_for_no_other_jobs_running()
{
	cat >"$_TEST_TMPDIR/squeue" <<EOF
#!/bin/sh

cat <<EOJ
42_2
42
EOJ
EOF
	chown root:root "$_TEST_TMPDIR/squeue"
	chmod 755 "$_TEST_TMPDIR/squeue"
	export PATH="$_TEST_TMPDIR:$PATH"

	assertFalse 'slurm_jobs_running_for test_user 42'
}

test_sleep_in_steps_for_break_out_early()
{
	assertTrue "step=0; sleep_in_steps_for 'step=\$((\$step + 1)); [ \$step -eq 5 ]' 10"
}
test_sleep_in_steps_for_never_break_out()
{
	assertFalse "step=0; sleep_in_steps_for 'step=\$((\$step + 1)); [ \$step -eq 12 ]' 10"
}

test_sleep_minimum_one_second_step_break_out_early()
{
	assertTrue "step=0; sleep_in_steps_for 'step=\$((\$step + 1)); [ \$step -eq 2 ]' 5"
}
test_sleep_minimum_one_second_step_never_break_out()
{
	assertFalse "step=0; sleep_in_steps_for 'step=\$((\$step + 1)); [ \$step -eq 7 ]' 5"
}

test_kill_leftover_user_procs_dont_kill_rc_admin_group()
{
	_setup_command_call_counter pkill

	cat >"$_TEST_TMPDIR/groups" <<EOF
#!/bin/sh

cat <<EOJ
foo bar rc_admin baz
EOJ
EOF
	chown root:root "$_TEST_TMPDIR/groups"
	chmod 755 "$_TEST_TMPDIR/groups"
	export PATH="$_TEST_TMPDIR:$PATH"

	PROCESS_KILL_WAIT_SECS=5

	assertTrue 'kill_leftover_user_procs test_user'
	assertNull "$(_command_calls pkill)"
}

test_kill_leftover_user_procs_dont_kill_if_other_jobs_running()
{
	_setup_command_call_counter pkill

	cat >"$_TEST_TMPDIR/squeue" <<EOF
#!/bin/sh

cat <<EOJ
69_2
42
EOJ
EOF
	export SLURM_JOB_ID=42

	chown root:root "$_TEST_TMPDIR/squeue"
	chmod 755 "$_TEST_TMPDIR/squeue"
	export PATH="$_TEST_TMPDIR:$PATH"

	PROCESS_KILL_WAIT_SECS=5

	assertTrue 'kill_leftover_user_procs test_user'
	assertNull "$(_command_calls pkill)"
}

test_kill_leftover_user_procs_exit_fast_if_no_procs_for_user()
{
	_setup_command_call_counter pkill

	cat >"$_TEST_TMPDIR/squeue" <<EOF
#!/bin/sh

cat <<EOJ
42
EOJ
EOF
	export SLURM_JOB_ID=42

	cat >"$_TEST_TMPDIR/ps" <<EOF
#!/bin/sh

exit 1
EOF
	chown root:root "$_TEST_TMPDIR/squeue" "$_TEST_TMPDIR/ps"
	chmod 755 "$_TEST_TMPDIR/squeue" "$_TEST_TMPDIR/ps"
	export PATH="$_TEST_TMPDIR:$PATH"

	PROCESS_KILL_WAIT_SECS=5

	assertTrue 'kill_leftover_user_procs test_user'
	assertNull "$(_command_calls pkill)"
}

test_kill_leftover_user_procs_user_has_procs_after_TERM_and_KILL()
{
	_setup_command_call_counter ps
	_setup_command_call_counter pkill
	_setup_command_call_counter scontrol

	cat >"$_TEST_TMPDIR/squeue" <<EOF
#!/bin/sh

cat <<EOJ
42
EOJ
EOF
	export SLURM_JOB_ID=42

	chown root:root "$_TEST_TMPDIR/squeue"
	chmod 755 "$_TEST_TMPDIR/squeue"
	export PATH="$_TEST_TMPDIR:$PATH"

	PROCESS_KILL_WAIT_SECS=5

	assertFalse 'kill_leftover_user_procs test_user'

	assertEquals '--no-headers -u test_user
--no-headers -u test_user
--no-headers -u test_user
--no-headers -u test_user
--no-headers -u test_user
--no-headers -u test_user
--no-headers -u test_user
--no-headers -u test_user
--no-headers -u test_user
--no-headers -u test_user
--no-headers -u test_user
-u test_user' "$(_command_calls ps)"

	assertEquals '-TERM -U test_user
-KILL -U test_user' "$(_command_calls pkill)"

	assertEquals \
		"update node=$(hostname -s) state=drain reason=test_user procs still running" \
		"$(_command_calls scontrol)"
}

usage()
{
	echo "Usage: $progname [-h] [-t]"
	echo '    -h Display this help message and exit.'
	echo '    -t Run built-in automated tests (requires shunit2).'
}

run_tests=0
while getopts ht ch; do
	case $ch in
	h)
		usage
		exit 0
		;;
	t)
		run_tests=1
		;;
	esac
done
if [ $OPTIND -gt 1 ]; then
	shift $(($OPTIND - 1))
fi

if [ $# -gt 0 ]; then
	usage
	exit 1
fi

if [ $HOSTNAME == "holybicep01.rc.fas.harvard.edu" ] || [ $HOSTNAME == "holy2a24208.rc.fas.harvard.edu" ] || [ $HOSTNAME == "holy2a21302.rc.fas.harvard.edu" ]; then
    echo "$HOSTNAME: exempt from epilog due to development node." | log
    exit 0
fi

if [ "$run_tests" -eq 1 ]; then
	uid=$(id -u)
	if [ "$uid" -ne 0 ]; then
		echo "$progname: tests must be run as root." 1>&2
		exit 1
	fi

	if ! _TEST_TMPDIR=$(mktemp -dt $progname.XXXXXXXXXX); then
		echo 'Unable to create temporary directory.' 1>&2
		exit 1
	fi
	trap "rm -r '$_TEST_TMPDIR'" EXIT

	. shunit2
	exit
fi

echo "Starting epilog for job $SLURM_JOB_ID by $SLURM_JOB_USER..." | log

if [ -z "$SLURM_UID" ] || [ -z "$SLURM_JOB_ID" ]; then
	exit 0
fi

# Don't try to kill user root or system daemon jobs.
if [ "$SLURM_UID" -ge 100 ]; then
	# Kill any user processes on this node when the last SLURM job
	# ends.
	#
	# For example, if a user directly logs into an allocated node,
	# SLURM will not kill that process without this being executed
	# in the epilog.
	kill_leftover_user_procs "$SLURM_JOB_USER"
fi

sync

echo "Epilog for job $SLURM_JOB_ID by $SLURM_JOB_USER complete." | log

exit 0
