#!/bin/sh

# SLURM runs this HealthCheckProgram on each compute node. If we find a
# problem, drain the node and provide a reason why.
#
# This script will also remediate problems if they are cleared up. NHC
# itself will reopen nodes if it finds the problem resolved. Similarly
# this script has other scenarios that it will reopen nodes when it
# knows the problem is passed.

# nhc is in /usr/sbin by default.
export PATH="$PATH:/sbin:/usr/sbin"
hostname=$(hostname -s)

# Function drain node
drain_node()
{
	local reason=$1
	shift

    if [ -z "$(scontrol show node $hostname | grep Reason)" ]; then
        scontrol update nodename="$hostname" state=drain reason="$reason"
    fi
}

# Function to resume node
resume_node()
{
  scontrol update state=resume nodename="$hostname"
}

# Node Health Checker
# If NHC returns unsuccessfully, there's some problem with this node.
if ! reason=$(timeout -s 9 40s nhc); then
	# Get rid of the leading text and replaces it with NHC:
    # This is needed for the automatic node_online script to work.
	reason=$(echo "$reason" |
		sed 's/^[[:space:]]*ERROR:  nhc:  Health check failed:[^:]\{1,\}:[[:space:]]*//')

    reason=$(echo "NHC: $reason")

	drain_node "$reason"
	exit 0
fi

# Other Drain Node Checks
<% if @check_kernel %>
if [ "$(uname -r)" != "<%= @kernel_version %>" ]; then
	reason="kernel version != <%= @kernel_version %>"
	drain_node "$reason"
	exit 0
fi
<% end %>

<% if @check_centos %>
if [ "$(lsb_release -r -s)" != "<%= @centos_release %>" ]; then
	reason="centos release != <%= @centos_release %>"
	drain_node "$reason"
	exit 0
fi
<% end %>

<% if @lustre_node and @check_lustre %>
if [ "$(rpm --qf '%{version}-%{release}\n' -q lustre-client)" != "<%= @lustre_version %>" ]; then
	reason="lustre-client rpm version != <%= @lustre_version %>"
	drain_node "$reason"
	exit 0
fi

lustre_module_version=$(modinfo -F version lustre)

if [ "$(rpm --qf '%{version}\n' -q lustre-client)" != "${lustre_module_version}" ]; then
	reason="lustre kernel module version != ${lustre_module_version}"
	drain_node "$reason"
	exit 0
fi
<% end %>

# Checking cgroups version
if [ "$(stat -fc %T /sys/fs/cgroup/)" != "cgroup2fs" ]; then
    reason="cgroups is not version 2"
	drain_node "$reason"
	exit 0
fi

# Checking the CPU Frequency is boosting when under load
mhz=$(cat /proc/cpuinfo | grep "cpu MHz" | sort -V | tail -n 1 | cut -d ":" -f 2 | sed 's/ //g')
load=$(cat /proc/loadavg | cut -d " " -f 1)
mhzlimit=1300.0
loadlimit=16.0

if [ $(echo "$load > $loadlimit" | bc) -eq 1 ]
then
	if [ $(echo "$mhz < $mhzlimit" | bc) -eq 1 ]
	then
		reason="cpu running at ${mhz} MHz under load of ${load}"
                drain_node "$reason"
                exit 0
	fi
fi

score=$(scontrol --oneliner show node $(hostname -s) | grep -o 'CPUTot=[^ ]*' | cut -d "=" -f 2)
pcore=$(nproc --all)

if [ $score != $pcore ]
then
        reason="Slurm has a different number of cores defined than the system does"
        drain_node "$reason"
        exit 0
fi

<% if @ib_island == 'holyhdr' or @ib_island == 'holyib' or @ib_island == 'fasse' %>
lnetib=$(lnetctl net show | grep ib)
if [ -z "$lnetib" ]
then
  reason="Node has infiniband but Lustre is not using it"
  drain_node "$reason"
  exit 0
fi
<% end %>

<% if @ib_island == 'holyhdr' %>
netmask=$(ifconfig ib0 | grep 255.255.224.0)
if [ -z "$netmask" ]
then
  reason="Node has incorrect IB Netmask"
  drain_node "$reason"
  exit 0
fi
<% end %>

<% if @role == 'role::compute::gpu' %>
gpuerr=$(nvidia-smi | grep -i Err)
if [ -n "$gpuerr" ]
then
  reason="GPU Error Detected"
  drain_node "$reason"
fi

peermem=$(lsmod | grep nvidia_peermem)
if [ -z "$peermem" ]
then
  systemctl restart nvidia-peermem
  peermem=$(lsmod | grep nvidia_peermem)
  if [ -z "$peermem" ]
  then
    reason="nvidia-peermem kernel module not started"
	drain_node "$reason"
  fi
fi
<% end %>

# Resume Node Checks
# First check if there is a reason
reason=$(scontrol show node $hostname | grep Reason)
if [ -n "$reason" ]
then
  # Kill task fail
  if [ -n "$(echo $reason | grep 'Kill task failed')" ]
  then
    # If the load is below a threshold then reopen
    load=$(cat /proc/loadavg | cut -d ' ' -f 1)
    threshold=0.9
    if (( $(echo "$load < $threshold" | bc -l) ))
    then
      resume_node
      exit 0
    fi
  fi

  # Prolog error
  if [ -n "$(echo $reason | grep 'Prolog error')" ]
  then
    # If the load is below a threshold then reopen
    load=$(cat /proc/loadavg | cut -d ' ' -f 1)
    threshold=0.9
    if (( $(echo "$load < $threshold" | bc -l) ))
    then
      resume_node
      exit 0
    fi
  fi

  # Job env setup error
  if [ -n "$(echo $reason | grep 'Job env setup error')" ]
  then
    # If the load is below a threshold then reopen
    load=$(cat /proc/loadavg | cut -d ' ' -f 1)
    threshold=0.9
    if (( $(echo "$load < $threshold" | bc -l) ))
    then
      resume_node
      exit 0
    fi
  fi
fi

exit 0
